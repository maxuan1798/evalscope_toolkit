# ğŸš€ Evalscope Toolkit

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![GitHub](https://img.shields.io/badge/GitHub-evalscope--toolkit-blue?logo=github)](https://github.com/maxuan1798/evalscope_toolkit)

ä¸€ä¸ªç®€åŒ–çš„ã€æ¨¡å—åŒ–çš„å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°å·¥å…·åŒ…ï¼ŒåŸºäº vLLM å’Œ Evalscope æ„å»ºã€‚

## âœ¨ ç‰¹æ€§

- ğŸ¯ **ç®€å•æ˜“ç”¨** - åªéœ€é…ç½®æ¨¡å‹å’Œæ•°æ®é›†å³å¯å¼€å§‹è¯„ä¼°
- ğŸ“¦ **æ¨¡å—åŒ–è®¾è®¡** - æ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•
- ğŸ”„ **è‡ªåŠ¨åŒ–æµç¨‹** - è‡ªåŠ¨ç®¡ç†æ•°æ®é›†ã€vLLM æœåŠ¡å’Œè¯„ä¼°æµç¨‹
- ğŸ“Š **å¤šæ•°æ®é›†æ”¯æŒ** - å†…ç½® 10+ ç§æ ‡å‡†è¯„ä¼°æ•°æ®é›†
- ğŸ¨ **å¤šç§ä½¿ç”¨æ–¹å¼** - Notebookã€Python è„šæœ¬ã€å‘½ä»¤è¡Œå‡å¯
- ğŸ›¡ï¸ **å¥å£®å¯é ** - å®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

## ğŸ¯ æ”¯æŒçš„æ•°æ®é›†

| æ•°æ®é›† | ç±»å‹ | æè¿° |
|--------|------|------|
| `gsm8k` | æ•°å­¦æ¨ç† | å°å­¦æ•°å­¦é—®é¢˜ |
| `humaneval` | ä»£ç ç”Ÿæˆ | Python ä»£ç ç”Ÿæˆ |
| `mmlu` | é€šè¯†çŸ¥è¯† | å¤šä»»åŠ¡è¯­è¨€ç†è§£ |
| `competition_math` | æ•°å­¦ | ç«èµ›çº§æ•°å­¦é—®é¢˜ |
| `drop` | é˜…è¯»ç†è§£ | ç¦»æ•£æ¨ç† |
| `hellaswag` | å¸¸è¯†æ¨ç† | å¥å­è¡¥å…¨ |
| `arc` | ç§‘å­¦ | AI2 æ¨ç†æŒ‘æˆ˜ |
| `truthfulqa` | çœŸå®æ€§ | çœŸå®æ€§é—®ç­” |
| `winogrande` | å¸¸è¯† | Winograd æ¨¡å¼ |
| `math_500` | æ•°å­¦ | æ•°å­¦é—®é¢˜é›† |

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: Notebookï¼ˆæ¨èï¼‰

```bash
git clone https://github.com/maxuan1798/evalscope_toolkit.git
cd evalscope_toolkit
jupyter notebook eval.ipynb
```

åœ¨ Notebook ä¸­ç›´æ¥è¿è¡Œè¯„ä¼°ä»£ç ã€‚

### æ–¹å¼ 2: Python è„šæœ¬

```python
from evalscope_toolkit import EvalConfig, Evaluator

# é…ç½®è¯„ä¼°
config = EvalConfig(
    models=["unsloth/Llama-3.2-3B-Instruct"],
    datasets=["gsm8k", "humaneval"],
    gpus="0",
    gpu_memory_utilization=0.6
)

# è¿è¡Œè¯„ä¼°
evaluator = Evaluator(config)
results = evaluator.run()
```

### æ–¹å¼ 3: å‘½ä»¤è¡Œ

```bash
python -m evalscope_toolkit.cli \
    --models "model1,model2" \
    --datasets "gsm8k,humaneval" \
    --gpus "0,1"
```

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
evalscope_toolkit/
â”œâ”€â”€ evalscope_toolkit/              # æ ¸å¿ƒ Python åŒ…
â”‚   â”œâ”€â”€ __init__.py                # åŒ…åˆå§‹åŒ–ï¼Œå¯¼å‡ºä¸»è¦ç±»
â”‚   â”œâ”€â”€ config.py                  # EvalConfig - é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ dataset_manager.py         # DatasetManager - æ•°æ®é›†ç®¡ç†
â”‚   â”œâ”€â”€ vllm_service.py            # VLLMService - vLLM æœåŠ¡ç®¡ç†
â”‚   â”œâ”€â”€ evaluator.py               # Evaluator - è¯„ä¼°ç¼–æ’
â”‚   â”œâ”€â”€ utils.py                   # å·¥å…·å‡½æ•°ï¼ˆä¾èµ–å®‰è£…ç­‰ï¼‰
â”‚   â””â”€â”€ cli.py                     # å‘½ä»¤è¡Œæ¥å£
â”‚
â”œâ”€â”€ eval.ipynb                     # åŸç‰ˆå®Œæ•´ Notebook
â”œâ”€â”€ setup.py                       # Python åŒ…å®‰è£…é…ç½®
â”œâ”€â”€ README.md                      # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ .gitignore                     # Git å¿½ç•¥æ–‡ä»¶
```

## ğŸ”§ å®‰è£…ä¾èµ–

### ç³»ç»Ÿè¦æ±‚
- Python 3.9+
- CUDA 11.8+ (GPU æ¨ç†)
- 8GB+ GPU å†…å­˜ï¼ˆå°æ¨¡å‹ï¼‰

### ä¾èµ–å®‰è£…
```bash
pip install torch vllm evalscope modelscope datasets
```

æˆ–ä»æºç å®‰è£…ï¼š
```bash
git clone https://github.com/maxuan1798/evalscope_toolkit.git
cd evalscope_toolkit
pip install -e .
```

## ğŸ“Š æ ¸å¿ƒæ¶æ„

```
1. é…ç½®åˆ›å»º (EvalConfig)
   â†“
2. æ•°æ®é›†å‡†å¤‡ (DatasetManager)
   - ä¸‹è½½æ•°æ®é›†
   - éªŒè¯ç¼“å­˜
   â†“
3. æ¨¡å‹è¯„ä¼°å¾ªç¯
   â”œâ”€ å¯åŠ¨ vLLM æœåŠ¡ (VLLMService)
   â”œâ”€ æ•°æ®é›†è¯„ä¼°å¾ªç¯
   â”‚  â”œâ”€ è°ƒç”¨ evalscope è¯„ä¼°
   â”‚  â””â”€ è®°å½•ç»“æœå’Œæ—¶é—´
   â””â”€ åœæ­¢ vLLM æœåŠ¡
   â†“
4. ç”ŸæˆæŠ¥å‘Š
   - evaluation_summary.json
   - overall_evaluation_times.log
```

## ğŸ“ é…ç½®ç¤ºä¾‹

### åŸºç¡€é…ç½®
```python
config = EvalConfig(
    models=["unsloth/Llama-3.2-3B-Instruct"],
    datasets=["gsm8k"],
)
```

### é«˜çº§é…ç½®
```python
config = EvalConfig(
    # æ¨¡å‹å’Œæ•°æ®é›†
    models=["model1", "model2", "/path/to/local/model"],
    datasets=["gsm8k", "humaneval", "mmlu"],
    
    # GPU é…ç½®
    gpus="0,1",                      # ä½¿ç”¨çš„ GPU
    tensor_parallel_size=2,          # å¼ é‡å¹¶è¡Œå¤§å°
    gpu_memory_utilization=0.6,      # GPU å†…å­˜åˆ©ç”¨ç‡
    
    # è¯„ä¼°å‚æ•°
    eval_batch_size=32,              # æ‰¹æ¬¡å¤§å°
    max_new_tokens=2048,             # æœ€å¤§ç”Ÿæˆ token æ•°
    temperature=0.0,                 # é‡‡æ ·æ¸©åº¦
    
    # è·¯å¾„é…ç½®
    data_root=Path("./data"),        # æ•°æ®ç¼“å­˜ç›®å½•
    log_root=Path("./log"),          # æ—¥å¿—ç›®å½•
)
```

## ğŸ ä¸»è¦æ”¹è¿›

### ç›¸æ¯”åŸç‰ˆ Notebook

| ç‰¹æ€§ | åŸç‰ˆ | Evalscope Toolkit |
|------|------|-------------------|
| ä»£ç ç»“æ„ | 500+ è¡Œå•æ–‡ä»¶ | æ¨¡å—åŒ– 7 ä¸ªæ–‡ä»¶ |
| å¯å¤ç”¨æ€§ | âŒ | âœ… å¯ä½œä¸ºåŒ…å¯¼å…¥ |
| é…ç½®ç®¡ç† | åˆ†æ•£åœ¨å„å¤„ | ç»Ÿä¸€é…ç½®ç±» |
| é”™è¯¯å¤„ç† | åŸºç¡€ | å®Œå–„çš„å¼‚å¸¸å¤„ç† |
| å‘½ä»¤è¡Œæ”¯æŒ | âŒ | âœ… |
| æ–‡æ¡£ | åŸºç¡€ | å®Œæ•´æ–‡æ¡£ + ç¤ºä¾‹ |
| è¶…æ—¶ç­–ç•¥ | å›ºå®š 300s | æ™ºèƒ½è¶…æ—¶ (3-10min) |

### æ ¸å¿ƒä¼˜åŒ–

âœ… **ç®€åŒ–çš„å¯åŠ¨æµç¨‹** - æ™ºèƒ½è¶…æ—¶ç­–ç•¥ï¼Œè¿œç¨‹æ¨¡å‹ 10 åˆ†é’Ÿï¼Œæœ¬åœ°æ¨¡å‹ 3 åˆ†é’Ÿ  
âœ… **æ›´å¥½çš„é”™è¯¯æç¤º** - å¤±è´¥æ—¶æ˜¾ç¤ºå…³é”®æ—¥å¿—ï¼Œå¿«é€Ÿå®šä½é—®é¢˜  
âœ… **è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜** - è‡ªåŠ¨ä¸‹è½½æ•°æ®é›†ã€ç®¡ç†æœåŠ¡ã€ç”ŸæˆæŠ¥å‘Š  
âœ… **æ¸…æ™°çš„è¿›åº¦åé¦ˆ** - å®æ—¶æ˜¾ç¤ºè¯„ä¼°è¿›åº¦å’Œå‰©ä½™æ—¶é—´  

## ğŸ“‚ è¾“å‡ºç»“æœ

è¯„ä¼°ç»“æœä¿å­˜åœ¨ `log/outputs_<ç”¨æˆ·>_<å®ä¾‹ID>/` ç›®å½•ï¼š

```
log/outputs_user_111412531924263/
â”œâ”€â”€ evaluation_summary.json          # è¯„ä¼°æ‘˜è¦
â”œâ”€â”€ overall_evaluation_times.log     # æ€»ä½“æ—¶é—´æ—¥å¿—
â”œâ”€â”€ vllm_<hash>.log                  # vLLM æœåŠ¡æ—¥å¿—
â””â”€â”€ model-name/
    â”œâ”€â”€ evaluation_times.log         # æ¨¡å‹è¯„ä¼°æ—¶é—´
    â”œâ”€â”€ gsm8k/
    â”‚   â”œâ”€â”€ result.json              # è¯„ä¼°ç»“æœ
    â”‚   â””â”€â”€ predictions.jsonl        # é¢„æµ‹ç»“æœ
    â””â”€â”€ humaneval/
        â””â”€â”€ ...
```

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### ç«¯å£è¢«å ç”¨
ç¨‹åºä¼šè‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†ã€‚

### GPU å†…å­˜ä¸è¶³
é™ä½ `gpu_memory_utilization` å€¼ï¼š
```python
config = EvalConfig(
    gpu_memory_utilization=0.4,  # é™ä½åˆ° 40%
)
```

### æ¨¡å‹ä¸‹è½½æ…¢
ä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–è®¾ç½® HuggingFace é•œåƒï¼š
```bash
export HF_ENDPOINT=https://hf-mirror.com
```

### vLLM å¯åŠ¨å¤±è´¥
æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `vllm_<hash>.log`ï¼Œå¤±è´¥æ—¶ä¼šè‡ªåŠ¨æ˜¾ç¤ºæœ€å 50 è¡Œã€‚



## ğŸ¯ æ ¸å¿ƒæ¨¡å—è¯´æ˜

| æ¨¡å— | ç±» | åŠŸèƒ½ |
|------|-----|------|
| `config.py` | `EvalConfig` | ç»Ÿä¸€é…ç½®ç®¡ç†ï¼Œç¯å¢ƒå˜é‡è®¾ç½® |
| `dataset_manager.py` | `DatasetManager` | æ•°æ®é›†ä¸‹è½½ã€ç¼“å­˜å’ŒéªŒè¯ |
| `vllm_service.py` | `VLLMService` | vLLM æœåŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç† |
| `evaluator.py` | `Evaluator` | è¯„ä¼°æµç¨‹ç¼–æ’å’Œæ‰§è¡Œ |
| `utils.py` | - | ä¾èµ–æ£€æŸ¥ã€å®‰è£…ç­‰å·¥å…·å‡½æ•° |
| `cli.py` | - | å‘½ä»¤è¡Œæ¥å£ |

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: å•æ¨¡å‹å•æ•°æ®é›†
```python
from evalscope_toolkit import EvalConfig, Evaluator

config = EvalConfig(
    models=["unsloth/Llama-3.2-3B-Instruct"],
    datasets=["gsm8k"],
)

evaluator = Evaluator(config)
results = evaluator.run()
```

### ç¤ºä¾‹ 2: å¤šæ¨¡å‹å¤šæ•°æ®é›†
```python
config = EvalConfig(
    models=[
        "unsloth/Llama-3.2-3B-Instruct",
        "Qwen/Qwen2.5-7B-Instruct",
    ],
    datasets=["gsm8k", "humaneval", "mmlu"],
    gpus="0,1",
)

evaluator = Evaluator(config)
results = evaluator.run()
```

## ğŸŒŸ æœ€ä½³å®è·µ

### GPU å†…å­˜ç®¡ç†
```python
# å°æ¨¡å‹ (<7B)
config = EvalConfig(gpu_memory_utilization=0.8)

# ä¸­ç­‰æ¨¡å‹ (7B-13B)  
config = EvalConfig(gpu_memory_utilization=0.6)

# å¤§æ¨¡å‹ (>13B)
config = EvalConfig(gpu_memory_utilization=0.4)
```

### å¤š GPU é…ç½®
```python
# å•æ¨¡å‹å¤š GPU (å¼ é‡å¹¶è¡Œ)
config = EvalConfig(gpus="0,1", tensor_parallel_size=2)

# å• GPU
config = EvalConfig(gpus="0")
```

## ğŸ¯ æœªæ¥è§„åˆ’

- [ ] æ”¯æŒæ›´å¤šè¯„ä¼°æ•°æ®é›†
- [ ] æ·»åŠ è‡ªå®šä¹‰æ•°æ®é›†æ”¯æŒ
- [ ] å¹¶è¡Œè¯„ä¼°å¤šä¸ªæ¨¡å‹
- [ ] ç»“æœå¯è§†åŒ–å’Œå¯¹æ¯”åˆ†æ
- [ ] Web UI ç•Œé¢
- [ ] Docker å®¹å™¨åŒ–

## ğŸ“ è·å–å¸®åŠ©

- **GitHub Issues**: [æŠ¥å‘Šé—®é¢˜æˆ–åŠŸèƒ½è¯·æ±‚](https://github.com/maxuan1798/evalscope_toolkit/issues)
- **æ–‡æ¡£**: æŸ¥çœ‹ README.md
- **ç¤ºä¾‹**: `eval.ipynb`

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

```bash
git clone https://github.com/maxuan1798/evalscope_toolkit.git
cd evalscope_toolkit
pip install -e .
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- [vLLM](https://github.com/vllm-project/vllm) - é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“
- [Evalscope](https://github.com/modelscope/evalscope) - æ¨¡å‹è¯„ä¼°æ¡†æ¶
- [ModelScope](https://modelscope.cn/) - æ¨¡å‹å’Œæ•°æ®é›†å¹³å°

---

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¶é—´**: 2025-11-14  
**ç»´æŠ¤è€…**: [@maxuan1798](https://github.com/maxuan1798)

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ï¸ Starï¼



{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "426073fa",
   "metadata": {},
   "source": [
    "# ğŸš€ Evalscope Toolkit - æ¨¡å‹è¯„ä¼°\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-evalscope--toolkit-blue?logo=github)](https://github.com/maxuan1798/evalscope-toolkit)\n",
    "[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/maxuan1798/evalscope-toolkit/blob/main/LICENSE)\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹è¯„ä¼° notebookï¼ŒåŸºäº [Evalscope Toolkit](https://github.com/maxuan1798/evalscope-toolkit) å¼€æºé¡¹ç›®ã€‚\n",
    "\n",
    "## âœ¨ ç‰¹æ€§\n",
    "\n",
    "- ğŸ“¦ **å¼€ç®±å³ç”¨**ï¼šè‡ªåŠ¨ä¸‹è½½ä¾èµ–å’Œå·¥å…·åŒ…\n",
    "- ğŸ¯ **ç®€å•é…ç½®**ï¼šåªéœ€è®¾ç½®æ¨¡å‹å’Œæ•°æ®é›†å³å¯\n",
    "- ğŸ”„ **è‡ªåŠ¨åŒ–**ï¼šè‡ªåŠ¨ç®¡ç† vLLM æœåŠ¡å’Œè¯„ä¼°æµç¨‹\n",
    "- ğŸ“Š **å¤šæ•°æ®é›†**ï¼šæ”¯æŒ 10+ ç§è¯„ä¼°æ•°æ®é›†\n",
    "\n",
    "## ğŸ¯ æ”¯æŒçš„æ•°æ®é›†\n",
    "\n",
    "`gsm8k` (æ•°å­¦) | `humaneval` (ä»£ç ) | `mmlu` (é€šè¯†) | `competition_math` | `drop` | `hellaswag` | `arc` | `truthfulqa` | `winogrande` | `math_500`\n",
    "\n",
    "## ğŸ“‹ å¿«é€Ÿå¼€å§‹\n",
    "\n",
    "1. **è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼** - è‡ªåŠ¨å®‰è£…ä¾èµ–\n",
    "2. **é…ç½®æ¨¡å‹å’Œæ•°æ®é›†** - ä¿®æ”¹é…ç½®å•å…ƒæ ¼\n",
    "3. **è¿è¡Œè¯„ä¼°** - ä¸€é”®å¼€å§‹\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f87f105",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…ä¾èµ–å’Œä¸‹è½½å·¥å…·åŒ…\n",
    "\n",
    "âš ï¸ **é¦–æ¬¡è¿è¡Œæ—¶è¯·æ‰§è¡Œæ­¤å•å…ƒæ ¼**\n",
    "\n",
    "æ­¤å•å…ƒæ ¼å°†ï¼š\n",
    "- ä» GitHub å…‹éš†æ•´ä¸ªä»“åº“ï¼ˆåŒ…å« `evalscope_toolkit` å·¥å…·åŒ…ï¼‰\n",
    "- è‡ªåŠ¨å®‰è£…æ‰€éœ€çš„ä¾èµ–ï¼ˆtorch, vllm, evalscope ç­‰ï¼‰\n",
    "\n",
    "> ğŸ’¡ ä¹Ÿå¯ä»¥æ‰‹åŠ¨å…‹éš†ä»“åº“ï¼š\n",
    "> ```bash\n",
    "> git clone https://github.com/maxuan1798/evalscope_toolkit.git\n",
    "> cd evalscope_toolkit\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# GitHub ä»“åº“é…ç½®\n",
    "GITHUB_REPO = \"https://github.com/maxuan1798/evalscope_toolkit.git\"\n",
    "\n",
    "def verify_toolkit(toolkit_path):\n",
    "    \"\"\"éªŒè¯å·¥å…·åŒ…æ˜¯å¦å®Œæ•´\"\"\"\n",
    "    required_files = [\n",
    "        '__init__.py',\n",
    "        'config.py',\n",
    "        'dataset_manager.py',\n",
    "        'vllm_service.py',\n",
    "        'evaluator.py',\n",
    "        'utils.py',\n",
    "    ]\n",
    "    \n",
    "    for filename in required_files:\n",
    "        if not (toolkit_path / filename).exists():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"è®¾ç½®ç¯å¢ƒï¼šå…‹éš†ä»“åº“å’Œå®‰è£…ä¾èµ–\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"ç¯å¢ƒè®¾ç½®\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # æ£€æŸ¥å·¥å…·åŒ…æ˜¯å¦å­˜åœ¨\n",
    "    toolkit_path = Path.cwd() / \"evalscope_toolkit\"\n",
    "    \n",
    "    # å¦‚æœå·²å­˜åœ¨ä¸”å®Œæ•´ï¼Œè·³è¿‡ä¸‹è½½\n",
    "    if toolkit_path.exists() and verify_toolkit(toolkit_path):\n",
    "        print(\"âœ“ evalscope_toolkit å·²å­˜åœ¨ä¸”å®Œæ•´\")\n",
    "    else:\n",
    "        # ä¸‹è½½ä»“åº“\n",
    "        print(\"\\nğŸ“¦ å…‹éš† evalscope_toolkit ä»“åº“...\")\n",
    "        print(f\"ä»“åº“åœ°å€: {GITHUB_REPO}\")\n",
    "        \n",
    "        try:\n",
    "            # æ¸…ç†æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ä½†ä¸å®Œæ•´ï¼‰\n",
    "            if toolkit_path.exists():\n",
    "                print(\"æ¸…ç†æ—§çš„ä¸å®Œæ•´æ–‡ä»¶...\")\n",
    "                import shutil\n",
    "                shutil.rmtree(toolkit_path)\n",
    "            \n",
    "            # å…‹éš†ä»“åº“åˆ°çˆ¶ç›®å½•çš„ä¸´æ—¶ä½ç½®\n",
    "            result = subprocess.run(\n",
    "                ['git', 'clone', '--depth', '1', GITHUB_REPO, 'evalscope_toolkit_repo'],\n",
    "                check=True,\n",
    "                capture_output=True,\n",
    "                text=True\n",
    "            )\n",
    "            \n",
    "            # ç§»åŠ¨ evalscope_toolkit æ–‡ä»¶å¤¹åˆ°å½“å‰ç›®å½•\n",
    "            import shutil\n",
    "            repo_path = Path.cwd() / \"evalscope_toolkit_repo\"\n",
    "            src_toolkit = repo_path / \"evalscope_toolkit\"\n",
    "            \n",
    "            if src_toolkit.exists():\n",
    "                shutil.move(str(src_toolkit), str(toolkit_path))\n",
    "                print(\"âœ“ å·¥å…·åŒ…ä¸‹è½½æˆåŠŸ\")\n",
    "            else:\n",
    "                print(\"âš  ä»“åº“ä¸­æœªæ‰¾åˆ° evalscope_toolkit æ–‡ä»¶å¤¹\")\n",
    "                return False\n",
    "            \n",
    "            # æ¸…ç†ä¸´æ—¶ä»“åº“\n",
    "            if repo_path.exists():\n",
    "                shutil.rmtree(repo_path)\n",
    "                \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âš  Git å…‹éš†å¤±è´¥: {e}\")\n",
    "            print(\"\\nè¯·æ‰‹åŠ¨å…‹éš†ä»“åº“ï¼š\")\n",
    "            print(f\"  git clone {GITHUB_REPO}\")\n",
    "            print(f\"  ç„¶åå°† evalscope_toolkit æ–‡ä»¶å¤¹å¤åˆ¶åˆ°å½“å‰ç›®å½•\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"âš  ä¸‹è½½å¤±è´¥: {e}\")\n",
    "            print(\"\\nè¯·æ‰‹åŠ¨å…‹éš†ä»“åº“ï¼š\")\n",
    "            print(f\"  git clone {GITHUB_REPO}\")\n",
    "            return False\n",
    "    \n",
    "    # æ·»åŠ åˆ° Python è·¯å¾„\n",
    "    cwd_str = str(Path.cwd())\n",
    "    if cwd_str not in sys.path:\n",
    "        sys.path.insert(0, cwd_str)\n",
    "    \n",
    "    # éªŒè¯å¯ä»¥å¯¼å…¥\n",
    "    try:\n",
    "        import evalscope_toolkit\n",
    "        print(\"âœ“ æˆåŠŸå¯¼å…¥ evalscope_toolkit\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âš  æ— æ³•å¯¼å…¥ evalscope_toolkit: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # å®‰è£…ä¾èµ–\n",
    "    print(\"\\nğŸ“¦ å®‰è£…ä¾èµ–...\")\n",
    "    try:\n",
    "        from evalscope_toolkit.utils import setup_dependencies\n",
    "        if setup_dependencies():\n",
    "            print(\"\\nâœ“ ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\nâš  éƒ¨åˆ†ä¾èµ–å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš  å®‰è£…ä¾èµ–å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# æ‰§è¡Œç¯å¢ƒè®¾ç½®\n",
    "if setup_environment():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ“ å‡†å¤‡å°±ç»ªï¼è¯·ç»§ç»­ä¸‹ä¸€æ­¥é…ç½®\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš  ç¯å¢ƒè®¾ç½®é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a66e90",
   "metadata": {},
   "source": [
    "## 2. é…ç½®æ¨¡å‹å’Œæ•°æ®é›†\n",
    "\n",
    "åœ¨è¿™é‡Œé…ç½®æ‚¨è¦è¯„ä¼°çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ç¡®ä¿å½“å‰ç›®å½•åœ¨ Python è·¯å¾„ä¸­\n",
    "cwd = str(Path.cwd())\n",
    "if cwd not in sys.path:\n",
    "    sys.path.insert(0, cwd)\n",
    "\n",
    "# é‡æ–°åŠ è½½æ¨¡å—ï¼ˆå¦‚æœä¹‹å‰å·²åŠ è½½ï¼‰\n",
    "if 'evalscope_toolkit' in sys.modules:\n",
    "    import importlib\n",
    "    importlib.reload(sys.modules['evalscope_toolkit'])\n",
    "\n",
    "from evalscope_toolkit import EvalConfig\n",
    "\n",
    "# ============================================================\n",
    "# é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„éœ€æ±‚ä¿®æ”¹ä»¥ä¸‹é…ç½®\n",
    "# ============================================================\n",
    "\n",
    "# æ¨¡å‹é…ç½®ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªæ¨¡å‹ï¼Œç”¨åˆ—è¡¨å½¢å¼ï¼‰\n",
    "MODELS = [\n",
    "    \"unsloth/Llama-3.2-3B-Instruct\",  # HuggingFace æ¨¡å‹ ID\n",
    "    # \"/path/to/local/model\",          # æˆ–æœ¬åœ°æ¨¡å‹è·¯å¾„\n",
    "]\n",
    "\n",
    "# æ•°æ®é›†é…ç½®ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªæ•°æ®é›†ï¼‰\n",
    "DATASETS = [\n",
    "    \"gsm8k\",           # æ•°å­¦æ¨ç†\n",
    "    # \"humaneval\",     # ä»£ç ç”Ÿæˆ\n",
    "    # \"mmlu\",          # å¤šä»»åŠ¡è¯­è¨€ç†è§£\n",
    "]\n",
    "\n",
    "# GPU é…ç½®\n",
    "GPUS = \"0\"              # ä½¿ç”¨çš„ GPU IDï¼Œä¾‹å¦‚ \"0\" æˆ– \"0,1\"\n",
    "GPU_MEM_UTIL = 0.6      # GPU å†…å­˜åˆ©ç”¨ç‡ (0.0-1.0)\n",
    "\n",
    "# è¯„ä¼°å‚æ•°ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å€¼å³å¯ï¼‰\n",
    "EVAL_BATCH_SIZE = 32    # è¯„ä¼°æ‰¹æ¬¡å¤§å°\n",
    "MAX_NEW_TOKENS = 2048   # æœ€å¤§ç”Ÿæˆ token æ•°\n",
    "TEMPERATURE = 0.0       # é‡‡æ ·æ¸©åº¦\n",
    "\n",
    "# ============================================================\n",
    "# åˆ›å»ºé…ç½®å¯¹è±¡\n",
    "# ============================================================\n",
    "\n",
    "config = EvalConfig(\n",
    "    models=MODELS,\n",
    "    datasets=DATASETS,\n",
    "    gpus=GPUS,\n",
    "    gpu_memory_utilization=GPU_MEM_UTIL,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "print(\"é…ç½®ä¿¡æ¯ï¼š\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æ¨¡å‹: {config.models}\")\n",
    "print(f\"æ•°æ®é›†: {config.datasets}\")\n",
    "print(f\"GPU: {config.gpus}\")\n",
    "print(f\"GPU å†…å­˜åˆ©ç”¨ç‡: {config.gpu_memory_utilization}\")\n",
    "print(f\"æ•°æ®ç›®å½•: {config.data_root}\")\n",
    "print(f\"æ—¥å¿—ç›®å½•: {config.log_root}\")\n",
    "print(\"=\"*60)\n",
    "print(\"âœ“ é…ç½®å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949862d8",
   "metadata": {},
   "source": [
    "## 3. æŸ¥çœ‹æ”¯æŒçš„æ•°æ®é›†\n",
    "\n",
    "è¿è¡Œæ­¤å•å…ƒæ ¼å¯ä»¥æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†åŠå…¶æè¿°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d78533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ç¡®ä¿è·¯å¾„æ­£ç¡®\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from evalscope_toolkit import DatasetManager\n",
    "\n",
    "print(\"æ”¯æŒçš„æ•°æ®é›†ï¼š\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for dataset_name in DatasetManager.list_supported_datasets():\n",
    "    info = DatasetManager.get_dataset_info(dataset_name)\n",
    "    print(f\"\\nğŸ“Š {dataset_name}\")\n",
    "    print(f\"   {info['description']}\")\n",
    "    print(f\"   ModelScope: {info['ms_name']}\")\n",
    "    if info['subset_name']:\n",
    "        print(f\"   Subset: {info['subset_name']}\")\n",
    "    print(f\"   Split: {info['split']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4dc4e",
   "metadata": {},
   "source": [
    "## 4. è¿è¡Œè¯„ä¼°\n",
    "\n",
    "æ‰§è¡Œæ­¤å•å…ƒæ ¼å¼€å§‹è¯„ä¼°ã€‚è¯„ä¼°è¿‡ç¨‹åŒ…æ‹¬ï¼š\n",
    "1. ä¸‹è½½å’Œå‡†å¤‡æ•°æ®é›†\n",
    "2. å¯åŠ¨ vLLM æœåŠ¡\n",
    "3. è¿è¡Œè¯„ä¼°\n",
    "4. ç”Ÿæˆç»“æœæŠ¥å‘Š\n",
    "\n",
    "âš ï¸ **æ³¨æ„**ï¼šè¯„ä¼°å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå…·ä½“å–å†³äºæ¨¡å‹å¤§å°å’Œæ•°æ®é›†æ•°é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eab73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ç¡®ä¿è·¯å¾„æ­£ç¡®\n",
    "if str(Path.cwd()) not in sys.path:\n",
    "    sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "from evalscope_toolkit import Evaluator\n",
    "\n",
    "# åˆ›å»ºè¯„ä¼°å™¨\n",
    "evaluator = Evaluator(config)\n",
    "\n",
    "# è¿è¡Œè¯„ä¼°\n",
    "try:\n",
    "    results = evaluator.run()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ“ è¯„ä¼°å®Œæˆï¼\")\n",
    "    print(\"=\"*60)\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš  è¯„ä¼°å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91411961",
   "metadata": {},
   "source": [
    "## 5. æŸ¥çœ‹è¯„ä¼°ç»“æœ\n",
    "\n",
    "æŸ¥çœ‹è¯„ä¼°ç»“æœæ‘˜è¦å’Œè¯¦ç»†ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºè¯„ä¼°ç»“æœ\n",
    "evaluator.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cfb0b",
   "metadata": {},
   "source": [
    "## 6. è¯¦ç»†ç»“æœåˆ†æï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "æŸ¥çœ‹æ¯ä¸ªæ¨¡å‹å’Œæ•°æ®é›†çš„è¯¦ç»†è¯„ä¼°ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ceadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# è¯»å–è¯„ä¼°æ‘˜è¦\n",
    "summary_file = evaluator.base_log_dir / \"evaluation_summary.json\"\n",
    "\n",
    "if summary_file.exists():\n",
    "    with open(summary_file) as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"è¯„ä¼°æ‘˜è¦ï¼š\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"å®ä¾‹ ID: {summary['instance_id']}\")\n",
    "    print(f\"ç”¨æˆ· ID: {summary['user_id']}\")\n",
    "    print(f\"æ—¥å¿—ç›®å½•: {summary['log_dir']}\")\n",
    "    print(\"\\næ¨¡å‹è¯„ä¼°ç»“æœï¼š\")\n",
    "    \n",
    "    for model_name, model_results in summary['models'].items():\n",
    "        print(f\"\\nğŸ“Š æ¨¡å‹: {model_name}\")\n",
    "        \n",
    "        if 'error' in model_results:\n",
    "            print(f\"   âš  é”™è¯¯: {model_results['error']}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   æ€»è€—æ—¶: {model_results.get('total_duration', 0)} ç§’\")\n",
    "        print(\"   æ•°æ®é›†ç»“æœï¼š\")\n",
    "        \n",
    "        for dataset_name, dataset_results in model_results.get('datasets', {}).items():\n",
    "            print(f\"\\n   - {dataset_name}:\")\n",
    "            print(f\"     è€—æ—¶: {dataset_results['duration']} ç§’\")\n",
    "            print(f\"     å¼€å§‹æ—¶é—´: {dataset_results['start_time']}\")\n",
    "            print(f\"     ç»“æŸæ—¶é—´: {dataset_results['end_time']}\")\n",
    "            print(f\"     ç»“æœç›®å½•: {dataset_results['work_dir']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ°è¯„ä¼°æ‘˜è¦æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3ae9a",
   "metadata": {},
   "source": [
    "## ğŸ“– ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### å¦‚ä½•æ·»åŠ è‡ªå·±çš„æ¨¡å‹ï¼š\n",
    "```python\n",
    "MODELS = [\n",
    "    \"unsloth/Llama-3.2-3B-Instruct\",  # HuggingFace æ¨¡å‹\n",
    "    \"/path/to/your/local/model\",      # æœ¬åœ°æ¨¡å‹\n",
    "]\n",
    "```\n",
    "\n",
    "### å¦‚ä½•é€‰æ‹©æ•°æ®é›†ï¼š\n",
    "```python\n",
    "DATASETS = [\n",
    "    \"gsm8k\",        # æ•°å­¦æ¨ç†\n",
    "    \"humaneval\",    # ä»£ç ç”Ÿæˆ\n",
    "    \"mmlu\",         # é€šç”¨çŸ¥è¯†\n",
    "]\n",
    "```\n",
    "\n",
    "### GPU é…ç½®ï¼š\n",
    "- å• GPU: `GPUS = \"0\"`\n",
    "- å¤š GPU: `GPUS = \"0,1\"`\n",
    "- CPU æ¨¡å¼: `GPUS = \"\"`\n",
    "\n",
    "### ç»“æœä½ç½®ï¼š\n",
    "æ‰€æœ‰è¯„ä¼°ç»“æœä¿å­˜åœ¨ `log/outputs_<ç”¨æˆ·>_<å®ä¾‹ID>/` ç›®å½•ä¸‹ã€‚\n",
    "\n",
    "### å¸¸è§é—®é¢˜ï¼š\n",
    "1. **ç«¯å£è¢«å ç”¨**ï¼šç¨‹åºä¼šè‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£\n",
    "2. **GPU å†…å­˜ä¸è¶³**ï¼šé™ä½ `GPU_MEM_UTIL` å€¼\n",
    "3. **æ¨¡å‹ä¸‹è½½æ…¢**ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–è®¾ç½® HuggingFace é•œåƒ\n",
    "\n",
    "### è·å–å¸®åŠ©ï¼š\n",
    "å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–æäº¤ GitHub Issueã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

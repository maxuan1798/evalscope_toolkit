{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f87f105",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…ä¾èµ–å’Œä¸‹è½½å·¥å…·åŒ…\n",
    "\n",
    "âš ï¸ **é¦–æ¬¡è¿è¡Œæ—¶è¯·æ‰§è¡Œæ­¤å•å…ƒæ ¼**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# GitHub ä»“åº“é…ç½®ï¼ˆè¯·ä¿®æ”¹ä¸ºæ‚¨çš„å®é™…ä»“åº“åœ°å€ï¼‰\n",
    "GITHUB_REPO = \"https://github.com/maxuan1798/evalscope-toolkit.git\"  # æ›¿æ¢ä¸ºå®é™…ä»“åº“åœ°å€\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"è®¾ç½®ç¯å¢ƒï¼šå®‰è£…ä¾èµ–å’Œä¸‹è½½å·¥å…·åŒ…\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"ç¯å¢ƒè®¾ç½®\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # æ£€æŸ¥å·¥å…·åŒ…æ˜¯å¦å­˜åœ¨\n",
    "    toolkit_path = Path.cwd() / \"evalscope_toolkit\"\n",
    "    \n",
    "    if not toolkit_path.exists():\n",
    "        print(\"\\nğŸ“¦ ä¸‹è½½ evalscope_toolkit...\")\n",
    "        try:\n",
    "            # æ–¹æ³•1: ä½¿ç”¨ git clone\n",
    "            subprocess.run(\n",
    "                ['git', 'clone', '--depth', '1', GITHUB_REPO, 'temp_repo'],\n",
    "                check=True\n",
    "            )\n",
    "            import shutil\n",
    "            shutil.move('temp_repo/evalscope_toolkit', 'evalscope_toolkit')\n",
    "            shutil.rmtree('temp_repo')\n",
    "            print(\"âœ“ å·¥å…·åŒ…ä¸‹è½½æˆåŠŸ\")\n",
    "        except:\n",
    "            print(\"âš  è‡ªåŠ¨ä¸‹è½½å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨ä¸‹è½½ï¼š\")\n",
    "            print(f\"   git clone {GITHUB_REPO}\")\n",
    "            print(\"   ç„¶åå°† evalscope_toolkit æ–‡ä»¶å¤¹å¤åˆ¶åˆ°å½“å‰ç›®å½•\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"âœ“ evalscope_toolkit å·²å­˜åœ¨\")\n",
    "    \n",
    "    # æ·»åŠ åˆ° Python è·¯å¾„\n",
    "    if str(Path.cwd()) not in sys.path:\n",
    "        sys.path.insert(0, str(Path.cwd()))\n",
    "    \n",
    "    # å®‰è£…ä¾èµ–\n",
    "    print(\"\\nğŸ“¦ å®‰è£…ä¾èµ–...\")\n",
    "    try:\n",
    "        from evalscope_toolkit.utils import setup_dependencies\n",
    "        if setup_dependencies():\n",
    "            print(\"\\nâœ“ ç¯å¢ƒè®¾ç½®å®Œæˆï¼\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\nâš  éƒ¨åˆ†ä¾èµ–å®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš  å®‰è£…ä¾èµ–å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "# æ‰§è¡Œç¯å¢ƒè®¾ç½®\n",
    "if setup_environment():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ“ å‡†å¤‡å°±ç»ªï¼è¯·ç»§ç»­ä¸‹ä¸€æ­¥é…ç½®\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš  ç¯å¢ƒè®¾ç½®é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a66e90",
   "metadata": {},
   "source": [
    "## 2. é…ç½®æ¨¡å‹å’Œæ•°æ®é›†\n",
    "\n",
    "åœ¨è¿™é‡Œé…ç½®æ‚¨è¦è¯„ä¼°çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalscope_toolkit import EvalConfig\n",
    "\n",
    "# ============================================================\n",
    "# é…ç½®åŒºåŸŸ - è¯·æ ¹æ®æ‚¨çš„éœ€æ±‚ä¿®æ”¹ä»¥ä¸‹é…ç½®\n",
    "# ============================================================\n",
    "\n",
    "# æ¨¡å‹é…ç½®ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªæ¨¡å‹ï¼Œç”¨åˆ—è¡¨å½¢å¼ï¼‰\n",
    "MODELS = [\n",
    "    \"unsloth/Llama-3.2-3B-Instruct\",  # HuggingFace æ¨¡å‹ ID\n",
    "    # \"/path/to/local/model\",          # æˆ–æœ¬åœ°æ¨¡å‹è·¯å¾„\n",
    "]\n",
    "\n",
    "# æ•°æ®é›†é…ç½®ï¼ˆå¯ä»¥æ˜¯å¤šä¸ªæ•°æ®é›†ï¼‰\n",
    "DATASETS = [\n",
    "    \"gsm8k\",           # æ•°å­¦æ¨ç†\n",
    "    # \"humaneval\",     # ä»£ç ç”Ÿæˆ\n",
    "    # \"mmlu\",          # å¤šä»»åŠ¡è¯­è¨€ç†è§£\n",
    "]\n",
    "\n",
    "# GPU é…ç½®\n",
    "GPUS = \"0\"              # ä½¿ç”¨çš„ GPU IDï¼Œä¾‹å¦‚ \"0\" æˆ– \"0,1\"\n",
    "GPU_MEM_UTIL = 0.6      # GPU å†…å­˜åˆ©ç”¨ç‡ (0.0-1.0)\n",
    "\n",
    "# è¯„ä¼°å‚æ•°ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å€¼å³å¯ï¼‰\n",
    "EVAL_BATCH_SIZE = 32    # è¯„ä¼°æ‰¹æ¬¡å¤§å°\n",
    "MAX_NEW_TOKENS = 2048   # æœ€å¤§ç”Ÿæˆ token æ•°\n",
    "TEMPERATURE = 0.0       # é‡‡æ ·æ¸©åº¦\n",
    "\n",
    "# ============================================================\n",
    "# åˆ›å»ºé…ç½®å¯¹è±¡\n",
    "# ============================================================\n",
    "\n",
    "config = EvalConfig(\n",
    "    models=MODELS,\n",
    "    datasets=DATASETS,\n",
    "    gpus=GPUS,\n",
    "    gpu_memory_utilization=GPU_MEM_UTIL,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    ")\n",
    "\n",
    "print(\"é…ç½®ä¿¡æ¯ï¼š\")\n",
    "print(\"=\"*60)\n",
    "print(f\"æ¨¡å‹: {config.models}\")\n",
    "print(f\"æ•°æ®é›†: {config.datasets}\")\n",
    "print(f\"GPU: {config.gpus}\")\n",
    "print(f\"GPU å†…å­˜åˆ©ç”¨ç‡: {config.gpu_memory_utilization}\")\n",
    "print(f\"æ•°æ®ç›®å½•: {config.data_root}\")\n",
    "print(f\"æ—¥å¿—ç›®å½•: {config.log_root}\")\n",
    "print(\"=\"*60)\n",
    "print(\"âœ“ é…ç½®å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949862d8",
   "metadata": {},
   "source": [
    "## 3. æŸ¥çœ‹æ”¯æŒçš„æ•°æ®é›†\n",
    "\n",
    "è¿è¡Œæ­¤å•å…ƒæ ¼å¯ä»¥æŸ¥çœ‹æ‰€æœ‰æ”¯æŒçš„æ•°æ®é›†åŠå…¶æè¿°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d78533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalscope_toolkit import DatasetManager\n",
    "\n",
    "print(\"æ”¯æŒçš„æ•°æ®é›†ï¼š\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for dataset_name in DatasetManager.list_supported_datasets():\n",
    "    info = DatasetManager.get_dataset_info(dataset_name)\n",
    "    print(f\"\\nğŸ“Š {dataset_name}\")\n",
    "    print(f\"   {info['description']}\")\n",
    "    print(f\"   ModelScope: {info['ms_name']}\")\n",
    "    if info['subset_name']:\n",
    "        print(f\"   Subset: {info['subset_name']}\")\n",
    "    print(f\"   Split: {info['split']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec4dc4e",
   "metadata": {},
   "source": [
    "## 4. è¿è¡Œè¯„ä¼°\n",
    "\n",
    "æ‰§è¡Œæ­¤å•å…ƒæ ¼å¼€å§‹è¯„ä¼°ã€‚è¯„ä¼°è¿‡ç¨‹åŒ…æ‹¬ï¼š\n",
    "1. ä¸‹è½½å’Œå‡†å¤‡æ•°æ®é›†\n",
    "2. å¯åŠ¨ vLLM æœåŠ¡\n",
    "3. è¿è¡Œè¯„ä¼°\n",
    "4. ç”Ÿæˆç»“æœæŠ¥å‘Š\n",
    "\n",
    "âš ï¸ **æ³¨æ„**ï¼šè¯„ä¼°å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå…·ä½“å–å†³äºæ¨¡å‹å¤§å°å’Œæ•°æ®é›†æ•°é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eab73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalscope_toolkit import Evaluator\n",
    "\n",
    "# åˆ›å»ºè¯„ä¼°å™¨\n",
    "evaluator = Evaluator(config)\n",
    "\n",
    "# è¿è¡Œè¯„ä¼°\n",
    "try:\n",
    "    results = evaluator.run()\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ“ è¯„ä¼°å®Œæˆï¼\")\n",
    "    print(\"=\"*60)\n",
    "except Exception as e:\n",
    "    print(f\"\\nâš  è¯„ä¼°å¤±è´¥: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91411961",
   "metadata": {},
   "source": [
    "## 5. æŸ¥çœ‹è¯„ä¼°ç»“æœ\n",
    "\n",
    "æŸ¥çœ‹è¯„ä¼°ç»“æœæ‘˜è¦å’Œè¯¦ç»†ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1cf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ˜¾ç¤ºè¯„ä¼°ç»“æœ\n",
    "evaluator.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416cfb0b",
   "metadata": {},
   "source": [
    "## 6. è¯¦ç»†ç»“æœåˆ†æï¼ˆå¯é€‰ï¼‰\n",
    "\n",
    "æŸ¥çœ‹æ¯ä¸ªæ¨¡å‹å’Œæ•°æ®é›†çš„è¯¦ç»†è¯„ä¼°ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ceadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# è¯»å–è¯„ä¼°æ‘˜è¦\n",
    "summary_file = evaluator.base_log_dir / \"evaluation_summary.json\"\n",
    "\n",
    "if summary_file.exists():\n",
    "    with open(summary_file) as f:\n",
    "        summary = json.load(f)\n",
    "    \n",
    "    print(\"è¯„ä¼°æ‘˜è¦ï¼š\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"å®ä¾‹ ID: {summary['instance_id']}\")\n",
    "    print(f\"ç”¨æˆ· ID: {summary['user_id']}\")\n",
    "    print(f\"æ—¥å¿—ç›®å½•: {summary['log_dir']}\")\n",
    "    print(\"\\næ¨¡å‹è¯„ä¼°ç»“æœï¼š\")\n",
    "    \n",
    "    for model_name, model_results in summary['models'].items():\n",
    "        print(f\"\\nğŸ“Š æ¨¡å‹: {model_name}\")\n",
    "        \n",
    "        if 'error' in model_results:\n",
    "            print(f\"   âš  é”™è¯¯: {model_results['error']}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"   æ€»è€—æ—¶: {model_results.get('total_duration', 0)} ç§’\")\n",
    "        print(\"   æ•°æ®é›†ç»“æœï¼š\")\n",
    "        \n",
    "        for dataset_name, dataset_results in model_results.get('datasets', {}).items():\n",
    "            print(f\"\\n   - {dataset_name}:\")\n",
    "            print(f\"     è€—æ—¶: {dataset_results['duration']} ç§’\")\n",
    "            print(f\"     å¼€å§‹æ—¶é—´: {dataset_results['start_time']}\")\n",
    "            print(f\"     ç»“æŸæ—¶é—´: {dataset_results['end_time']}\")\n",
    "            print(f\"     ç»“æœç›®å½•: {dataset_results['work_dir']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "else:\n",
    "    print(\"æœªæ‰¾åˆ°è¯„ä¼°æ‘˜è¦æ–‡ä»¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e3ae9a",
   "metadata": {},
   "source": [
    "## ğŸ“– ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### å¦‚ä½•æ·»åŠ è‡ªå·±çš„æ¨¡å‹ï¼š\n",
    "```python\n",
    "MODELS = [\n",
    "    \"unsloth/Llama-3.2-3B-Instruct\",  # HuggingFace æ¨¡å‹\n",
    "    \"/path/to/your/local/model\",      # æœ¬åœ°æ¨¡å‹\n",
    "]\n",
    "```\n",
    "\n",
    "### å¦‚ä½•é€‰æ‹©æ•°æ®é›†ï¼š\n",
    "```python\n",
    "DATASETS = [\n",
    "    \"gsm8k\",        # æ•°å­¦æ¨ç†\n",
    "    \"humaneval\",    # ä»£ç ç”Ÿæˆ\n",
    "    \"mmlu\",         # é€šç”¨çŸ¥è¯†\n",
    "]\n",
    "```\n",
    "\n",
    "### GPU é…ç½®ï¼š\n",
    "- å• GPU: `GPUS = \"0\"`\n",
    "- å¤š GPU: `GPUS = \"0,1\"`\n",
    "- CPU æ¨¡å¼: `GPUS = \"\"`\n",
    "\n",
    "### ç»“æœä½ç½®ï¼š\n",
    "æ‰€æœ‰è¯„ä¼°ç»“æœä¿å­˜åœ¨ `log/outputs_<ç”¨æˆ·>_<å®ä¾‹ID>/` ç›®å½•ä¸‹ã€‚\n",
    "\n",
    "### å¸¸è§é—®é¢˜ï¼š\n",
    "1. **ç«¯å£è¢«å ç”¨**ï¼šç¨‹åºä¼šè‡ªåŠ¨å¯»æ‰¾å¯ç”¨ç«¯å£\n",
    "2. **GPU å†…å­˜ä¸è¶³**ï¼šé™ä½ `GPU_MEM_UTIL` å€¼\n",
    "3. **æ¨¡å‹ä¸‹è½½æ…¢**ï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–è®¾ç½® HuggingFace é•œåƒ\n",
    "\n",
    "### è·å–å¸®åŠ©ï¼š\n",
    "å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–æäº¤ GitHub Issueã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
